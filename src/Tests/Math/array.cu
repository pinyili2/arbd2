#include "Backend/Buffer.h"
#include "Backend/CUDA/CUDAManager.h"
#include "Backend/Events.h"
#include "Backend/Resource.h"
#include <cstdio>
#include <float.h>
#include <iostream>

#include "../catch_boiler.h"
#include "Math/Types.h"
#include <cuda.h>
#include <nvfunctional>

#include "../../extern/Catch2/extras/catch_amalgamated.hpp"

DEF_RUN_TRIAL

namespace Tests::TestArray {

template <typename T> __host__ __device__ void print_it(T x) {
  printf("Unsupported type\n");
}
template <> __host__ __device__ void print_it(const int x) {
  printf("int %d\n", x);
}
template <> __host__ __device__ void print_it(const long int x) {
  printf("long int %ld\n", x);
}
template <> __host__ __device__ void print_it(const float x) {
  printf("float %f\n", x);
}
template <> __host__ __device__ void print_it(const double x) {
  printf("double %lf\n", x);
}
template <>
__host__ __device__ void print_it(const ARBD::Vector3_t<float> &&x) {
  x.print();
}
template <> __host__ __device__ void print_it(const ARBD::Vector3_t<float> &x) {
  x.print();
}

// Simple has_copy_to_cuda trait for testing
template <typename T, typename = void>
struct has_copy_to_cuda : std::false_type {};

template <typename T>
struct has_copy_to_cuda<T, decltype(std::declval<T>().copy_to_cuda(), void())>
    : std::true_type {};

template <typename T> void print_enable_if_value() {
  if (has_copy_to_cuda<T>::value) {
    printf("has_copy_to_cuda is true\n");
  } else {
    printf("has_copy_to_cuda is false\n");
  }
}

template <typename T> ARBD::Array<T> allocate_array_host(size_t num) {
  ARBD::Array<T> arr(num);
  return arr;
}

template <typename T> T *allocate_plain_array_host(size_t num) {
  T *arr = new T[num];
  return arr;
}

template <typename T> T *allocate_plain_array_device(size_t num) {
  T *arr = allocate_plain_array_host<T>(num);
  T *arr_d;
  size_t sz = sizeof(T) * num;
  ARBD::check_cuda_error(cudaMalloc(&arr_d, sz), __FILE__, __LINE__);
  ARBD::check_cuda_error(cudaMemcpy(arr_d, arr, sz, cudaMemcpyHostToDevice),
                         __FILE__, __LINE__);
  delete[] arr;
  return arr_d;
}

template <typename T>
HOST DEVICE void inline _copy_helper(size_t &idx, T *__restrict__ out,
                                     const T *__restrict__ inp) {
  out[idx] = inp[idx];
}

// HOST DEVICE void inline _copy_helper(size_t& idx, float* __restrict__ out,
// const float* __restrict__ inp) { 	out[idx] = inp[idx];
// }
template <typename T>
HOST DEVICE void inline _copy_helper(size_t &idx,
                                     ARBD::Array<T> *__restrict__ out,
                                     const ARBD::Array<T> *__restrict__ inp) {
  (*out)[idx] = (*inp)[idx];
}

template <typename T>
__global__ void copy_kernel(size_t num, T *__restrict__ out,
                            const T *__restrict__ inp) {
  for (size_t i = threadIdx.x + blockIdx.x * blockDim.x; i < num;
       i += blockDim.x * gridDim.x) {
    _copy_helper(i, out, inp);
  }
}

template <typename T>
void call_copy_kernel(size_t num, T *__restrict__ out,
                      const T *__restrict__ inp, size_t block_size = 256) {
  copy_kernel<<<block_size, 1, 0>>>(num, out, inp);
  ARBD::check_cuda_error(cudaDeviceSynchronize(), __FILE__, __LINE__);
}

// Array<T> _copy_array_cuda(size_t num) {
// 	Array<T> arr(num);
// 	return arr;
// }

} // End namespace Tests::TestArray

TEST_CASE("Test Array assignment and basic operations", "[Array]") {
  {
    // Creation and copy assignment
    ARBD::Array<ARBD::Vector3_t<float>> a =
        Tests::TestArray::allocate_array_host<ARBD::Vector3_t<float>>(10);
  }

  {
    // Allocation and deallocation
    ARBD::VecArray a(10);
    a[0] = ARBD::Vector3(1);
    a[3] = ARBD::Vector3(3);

    // Just test basic array operations without CUDA for now
    REQUIRE(a[0].x == 1.0f);
    REQUIRE(a[3].x == 3.0f);

    Tests::TestArray::print_enable_if_value<int>();
    Tests::TestArray::print_enable_if_value<ARBD::Vector3_t<float>>();
    Tests::TestArray::print_enable_if_value<ARBD::VecArray>();
    Tests::TestArray::print_enable_if_value<ARBD::Array<ARBD::VecArray>>();
  }
}

TEST_CASE("Test Array nesting operations", "[Array]") {
  {
    // Allocation and deallocation - Create arrays first
    ARBD::VecArray v1(10);
    for (int i = 0; i < v1.size(); ++i) {
      v1[i] = ARBD::Vector3(i + 1);
    }
    ARBD::VecArray v2(20);
    for (int i = 0; i < v2.size(); ++i) {
      v2[i] = ARBD::Vector3(10 * i + 1);
    }

    // Test simple VecArray access first to ensure they work
    REQUIRE(v1[1].x == 2.0f);
    REQUIRE(v2[1].x == 11.0f);

    // Test nested array creation and assignment - now should work with fixed
    // copy assignment
    ARBD::Array<ARBD::VecArray> a(3);

    // Test that the nested array is functional
    REQUIRE(a.size() == 3);

    // Now test the fixed copy assignment - this should work without segfault
    a[0] = v1; // This now properly reallocates and copies
    a[1] = v2; // This now properly reallocates and copies

    // Test nested array access
    REQUIRE(a[0][1].x == 2.0f);
    REQUIRE(a[1][1].x == 11.0f);

    printf("Nested array assignment tests now working correctly!\n");
  }
}

TEST_CASE("Test basic CUDA kernels", "[Array]") {
  {
    // Test basic CUDA kernel operations
    size_t num = 1000;
    float *inp = Tests::TestArray::allocate_plain_array_device<float>(num);
    float *out = Tests::TestArray::allocate_plain_array_device<float>(num);

    Tests::TestArray::call_copy_kernel(num, out, inp);

    ARBD::check_cuda_error(cudaFree(inp), __FILE__, __LINE__);
    ARBD::check_cuda_error(cudaFree(out), __FILE__, __LINE__);

    REQUIRE(true); // Basic test that CUDA operations work
  }
}
